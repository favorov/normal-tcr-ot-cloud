# Project Context for GitHub Copilot

## Project Overview
TCR (T-cell receptor) analysis using Optimal Transport (Wasserstein distance) to compare probability distributions of generation probabilities (pgen) between patients.

**Key Achievement:** Mathematically consistent framework for analyzing distributions spanning 18 orders of magnitude (10⁻²⁴ to 10⁻⁶).

## Architecture

### Modular Design
**Core module:** `ot_utils.py` — centralized OT operations
- All scripts use same distance computation logic
- Single source of truth for metrics and algorithms
- Easy to swap OT libraries in the future

**Scripts:**
1. `olga-barycenter-ot.py` — compute Wasserstein barycenter
2. `olga-plot-barycenter.py` — visualize barycenter
3. `olga-p2p-ot.py` — pairwise distances (3 modes: single/one-to-all/all-pairs)
4. `olga-p2b-ot.py` — distances to barycenter (single/batch)

### Key Utilities (ot_utils.py)

```python
# Column finding with substring matching
_find_column_index(df, column_spec, param_name)
# Returns: column index
# Supports: exact match → substring match → numeric index
# Raises: ValueError with helpful diagnostic

# Load distribution from TSV
load_distribution(filepath, freq_column="pgen", weights_column="off")
# Returns: values (np.ndarray), weights (np.ndarray)
# Filters: positive values only, normalizes weights

# Core distance computation
compute_wasserstein_distance(values1, weights1, values2, weights2, 
                            metric='log_l1', method='emd')
# Returns: float (Wasserstein distance)
# Metric: 'log_l1' (default), 'l1', 'l2'
# Method: 'emd' (exact), 'sinkhorn' (fast approximate)

# Cost matrix computation
compute_cost_matrix(support1, support2, metric='log_l1')
# Returns: cost_matrix (np.ndarray)
# Used internally by compute_wasserstein_distance

# Discretize distribution onto grid
discretize_distribution(values, weights, grid)
# Returns: discretized_weights (np.ndarray)
# Maps continuous distribution to fixed grid via histogram

# Create common grid for multiple distributions
create_common_grid(values_list, n_grid=200, log_space=True)
# Returns: grid (np.ndarray)
# Log-spaced by default (critical for pgen data!)

# Load precomputed barycenter
load_barycenter(filepath)
# Returns: grid (np.ndarray), barycenter (np.ndarray)
# Loads from .npz file

# Extend grid for out-of-sample data
extend_grid_if_needed(grid, weights, new_data_min, new_data_max)
# Returns: extended_grid, extended_weights
# Preserves original grid points, adds new ones with zero weight
# Maintains logarithmic spacing

# Label helper for plots/tables
_label_from_filename(file_path)
# Returns: patient label like 01B or 17P based on Base/Post in filename
```

## Mathematical Foundation

### Why log_l1 Metric?

**Data characteristics:**
- pgen values: [1.42e-24, 3.54e-06] (18 orders of magnitude!)
- Standard L1 fails: `|1e-24 - 1e-23| ≈ 0` (suppressed)
- Standard L1 fails: `|1e-6 - 2e-6| = 1e-6` (dominates)

**Solution: log_l1 in logarithmic space**
```python
cost(x₁, x₂) = |log(x₁) - log(x₂)|
```

This treats all orders of magnitude fairly:
- `|log(1e-24) - log(1e-23)| ≈ 2.3`
- `|log(1e-6) - log(2e-6)| ≈ 0.69`

**Critical:** ALL components use log_l1:
- `ot_utils.compute_cost_matrix()` with `metric='log_l1'`
- `olga-barycenter-ot.py`: `cost_matrix = |log(grid) - log(grid.T)|`
- `olga-p2p-ot.py` and `olga-p2b-ot.py`: via `ot_utils`

### Grid Extension

**Problem:** Comparing new distribution to barycenter when new data extends beyond barycenter's grid range.

**Solution:** `extend_grid_if_needed()` automatically:
1. Calculates log-spacing step from original grid
2. Adds points below/above as needed
3. Preserves original grid exactly
4. Assigns zero weight to new points

**Example:**
```
Original grid: 200 points [1.42e-24, 3.54e-06]
New data: [5e-25, 1e-05]  # extends both directions
Extended grid: 272 points [9.77e-25, 1.14e-05]
  Added below: 57 points
  Added above: 15 points
  Log-spacing preserved: ✓
```

### Distribution Model

**Input format:**
- TSV files with pgen values (probability of generation)
- Optional weights column (e.g., duplicate_frequency_percent)
- Each row is one TCR sequence observation

**Representation:**
- Values: pgen measurements
- Weights: contribution of each measurement
- If weights='off': uniform weights (1/N for each)
- Normalized: Σ weights = 1.0

**Processing:**
1. Load values and weights from TSV
2. Filter: keep only positive values
3. Normalize: ensure weights sum to 1
4. Discretize onto common grid (for consistency)
5. Compute Wasserstein distance using EMD solver

## Column Finding Logic

**Three-stage resolution:**
```python
# Stage 1: Exact match
if "pgen" in df.columns:
    return df.columns.get_loc("pgen")

# Stage 2: Unique substring match
matches = [col for col in df.columns if "duplicate_frequency_p" in col]
if len(matches) == 1:
    return df.columns.get_loc(matches[0])
elif len(matches) > 1:
    raise ValueError(f"Ambiguous: {matches}")
else:
    raise ValueError(f"Not found. Available: {list(df.columns)}")

# Stage 3: Numeric index (if int)
if 0 <= column_spec < len(df.columns):
    return column_spec
```

**User-friendly:**
- `--weights-column duplicate_frequency_percent` — exact
- `--weights-column duplicate_frequency_p` — substring (unique)
- `--weights-column frequency_percent` — substring (unique)
- `--weights-column 18` — by index

**Error handling:**
- Ambiguous: shows all matches, asks for more specific name
- Not found: shows all available columns
- Out of range: shows valid range and column names

## Script Details

### Sample input handling (boxplot/MDS/p-value)

The scripts `olga-boxplot-samples-ot-2pb.py`, `olga-mds-plot-samples.py`, and
`olga-samples-p2b-pval.py` accept `samples` as either:
- A folder with TSV files, or
- A text file with one TSV path per line (supports `#` comments)

### olga-p2p-ot.py

**Three modes:**
```python
# Single pair
compute_distance_single_pair(folder, file1, file2, ...)

# One-to-all
compute_distance_one_to_all(folder, ref_file, ...)

# All-pairs (upper triangle only)
compute_distance_all_pairs(folder, ...)
```

**Key flags:**
- `--barycenter <file>`: Use grid from barycenter file (default: barycenter.npz, ensures consistency with p2b distances)
- `--pipeline`: Output only numbers (one per line)
- `--statistics-only`: Output only stats (no tables)

**Grid handling with --barycenter:**
1. Load barycenter grid from specified file
2. Find global min/max of all distributions to compare
3. Extend grid if needed via `extend_grid_if_needed()`
4. Use extended grid for all comparisons

### Sample input handling (boxplot/MDS/p-value)

The scripts `olga-boxplot-samples-ot-2pb.py`, `olga-mds-plot-samples.py`, and
`olga-samples-p2b-pval.py` accept `samples` as either:
- A folder with TSV files, or
- A text file with one TSV path per line (supports `#` comments)

**Custom labels in file lists:**
- Format: `path/to/file.tsv CustomLabel`
- Separator: any whitespace (space or tab)
- Behavior:
  * If label provided: use custom label exactly
  * If no label: auto-generate via `_label_from_filename()` (e.g., Patient01_Base → 01B)
- Implementation: `_load_sample_files()` returns `(files, output_folder, custom_labels)` dict
- Label retrieval: `custom_labels.get(file_path, _label_from_filename(file_path))`

**Example file list with custom labels:**
```text
# Mixed labels - some custom, some auto-generated
/data/cohort1/Patient01_Base_tcr_pgen.tsv    C1-P1
/data/cohort2/Patient01_Base_tcr_pgen.tsv    C2-P1
/data/Patient03_Base_tcr_pgen.tsv
# ^ Will auto-generate: 03B
```

### Visualization sizing and labels

**Figure dimensions (doubled 2x on each axis for clarity):**
- `olga-plot-barycenter.py`: 26 × 14 inches (was 13 × 7)
- `olga-boxplot-samples-ot-2pb.py`: 16 × 12 inches (was 8 × 6)
- `olga-mds-plot-samples.py`: 24 × 20 inches (was 12 × 10)

**Label positioning (to minimize overlap):**
- MDS: labels centered above points, vertical offset 0.04
- Boxplot: labels centered above points, vertical offset 0.025
- Boxplot point spread: jitter std = 0.08 for natural appearance

### olga-p2b-ot.py

**Modes:**
- Single file: distance from one file to barycenter
- Batch (`--all`): distances from all files to barycenter

**Process:**
```python
for file in files:
    values, weights = load_distribution(file, ...)
    
    # Auto-extend grid if data extends beyond barycenter
    extended_grid, extended_bary = extend_grid_if_needed(
        grid, barycenter_weights,
        values.min(), values.max()
    )
    
    # Discretize and compute distance
    sample_discretized = discretize_distribution(values, weights, extended_grid)
    distance = compute_wasserstein_distance(
        extended_grid, sample_discretized,
        extended_grid, extended_bary,
        metric='log_l1'
    )
```

**Output modes:**
- Normal: sorted table + statistics
- `--pipeline`: numbers only
- `--statistics-only`: stats only

### olga-barycenter-ot.py

**Process:**
```python
# 1. Load all distributions
for file in glob("*.tsv"):
    values, weights = load_distribution(file, ...)
    all_distributions.append((values, weights))

# 2. Create common log-spaced grid
grid = create_common_grid([v for v, w in all_distributions], n_grid=200)

# 3. Discretize all distributions onto grid
distributions_matrix = []
for values, weights in all_distributions:
    discretized = discretize_distribution(values, weights, grid)
    distributions_matrix.append(discretized)

# 4. Compute barycenter using LP solver
log_grid = np.log(grid)
cost_matrix = np.abs(log_grid.reshape(-1, 1) - log_grid.reshape(1, -1))
barycenter = ot.lp.barycenter(
    distributions_matrix.T,  # shape: (n_grid, n_distributions)
    cost_matrix,
    reg=1e-5
)

# 5. Save to .npz
np.savez(output_path, grid=grid, barycenter=barycenter)
```

**Critical:** Cost matrix uses log_l1 metric (consistent with ot_utils).

## Error Handling

**Parameter errors (ValueError) — always shown:**
```python
except ValueError as e:
    print(f"Error: {e}")
    sys.exit(1)
```

**Processing errors — mode-dependent:**
```python
except Exception as e:
    if not pipeline_mode:
        print(f"Error processing {file}: {e}")
    if not batch_mode:
        sys.exit(1)
    continue  # skip to next file
```

This ensures:
- Configuration errors always visible
- Processing errors don't break pipelines
- Single-file mode stops on any error
- Batch mode continues after processing errors

## Data Structure

**Input TSV columns (23 total):**
- Column 22: `pgen` — generation probability
- Column 17: `duplicate_count` — sequence duplicate count
- Column 18: `duplicate_frequency_percent` — frequency as percentage
- Others: sequence, v_call, j_call, junction, etc.

**Output files:**
- `barycenter.npz` — NumPy archive with keys: 'grid', 'barycenter'
- `barycenter_plot.png` — matplotlib visualization

## Environment

**Python 3.9+** with dependencies:
```bash
pip install numpy pandas pot matplotlib
```

**Virtual environment:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

## Testing Commands

```bash
# Unit test: column finding
python3 -c "from ot_utils import load_distribution; \
    load_distribution('input/.../Patient01.tsv', \
    weights_column='duplicate_frequency_p')"

# Integration test: p2b single file
python3 olga-p2b-ot.py input/test-cloud-Tumeh2014 \
    Patient01_Base_tcr_pgen.tsv --weights-column count

# Integration test: p2p all-pairs
python3 olga-p2p-ot.py input/test-cloud-Tumeh2014 \
    --all --barycenter barycenter.npz --statistics-only
```

## Design Patterns

### DRY Principle
All distance computations go through `ot_utils.compute_wasserstein_distance()`:
- Ensures metric consistency (log_l1)
- Single point of maintenance
- Easy to swap OT library

### Fail Fast
Parameter validation happens early:
- Column names validated on load
- Grid extensions computed before distance
- ValueError raised immediately with helpful message

### Progressive Enhancement
- Works without weights (uniform)
- Works without barycenter grid (creates adaptive)
- Works with out-of-sample data (auto-extends grid)
- Works in pipeline mode (minimal output)

## Future Considerations

- [ ] Parallel processing for all-pairs (joblib/multiprocessing)
- [ ] Alternative regularization for Sinkhorn
- [ ] Bootstrap confidence intervals
- [ ] CSV output format for distance matrices
- [ ] Optional KDE smoothing for sparse distributions

## Documentation

Full development history: `archive/copilot-chat.md`
